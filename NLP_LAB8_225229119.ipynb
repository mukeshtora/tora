{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbaaf34e",
   "metadata": {},
   "source": [
    "## EXERCISE-1: Exploring POS of Large Text Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5161d630",
   "metadata": {},
   "source": [
    "### 2. Tokenize your movie file and print the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bdd35ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'best', 'scene', 'in', 'Barry', 'Jenkins', '’', 's', 'Moonlight', 'is', 'also', 'its', 'longest', '.', 'It', 'depicts', 'two', 'men', 'who', ',', 'in', 'their', 'boyhood', 'days', ',', 'shared', 'both', 'a', 'sexual', 'experience', 'and', 'a', 'violent', 'episode', 'and', 'meet', 'again', 'after', 'years', 'apart', 'at', 'a', 'close-to-empty', 'diner', ',', 'hesitantly', 'exchanging', 'information', 'about', 'the', 'lives', 'they', '’', 've', 'lived', 'in', 'the', 'interim', '.', 'Chiron', '(', 'Trevante', 'Rhodes', ')', 'grits', 'through', 'his', 'grillz', 'that', ',', 'after', 'a', 'stint', 'in', 'juvenile', 'detention', ',', 'he', '’', 's', '“', 'trappin', '’', '”', ';', 'Kevin', '(', 'André', 'Holland', ')', 'talks', 'of', 'a', 'marriage', ',', 'kids', ',', 'and', 'an', 'amiable', 'divorce', '.', 'Throughout', ',', 'Jenkins', 'negotiates', 'a', 'hybrid', 'of', 'the', 'patient', ',', 'real-time', 'conversational', 'moments', 'recognizable', 'in', 'Andrew', 'Haigh', 'and', 'Richard', 'Linklater', '’', 's', 'films', ',', 'and', 'the', 'aesthetic', 'sensualism', 'favored', 'by', 'Wong', 'Kar-wai', 'and', 'Pedro', 'Almodóvar', '.', 'It', '’', 's', 'the', 'one', 'occasion', 'here', 'that', 'Jenkins', 'gets', 'that', 'balance', 'just', 'right', ',', 'allowing', 'for', 'both', 'an', 'interpersonal', 'intimacy', 'with', 'his', 'characters', 'and', 'a', 'sensory', 'understanding', 'of', 'their', 'unspoken', 'desires', '.', 'The', 'rest', 'of', 'Moonlight', ',', 'however', ',', 'is', 'burdened', 'with', 'not', 'only', 'setting', 'up', 'the', 'dramatic', 'weight', 'of', 'this', 'particular', 'encounter', ',', 'but', 'also', 'developing', 'the', 'narrative', 'leading', 'toward', 'another', 'one', ':', 'Chiron', '’', 's', 'reunion', 'with', 'his', 'drug-addicted', 'mother', ',', 'Paula', '(', 'Naomie', 'Harris', ')', '.', 'Because', 'Jenkins', 'has', 'tasked', 'himself', 'with', 'a', 'story', 'that', 'spans', 'three', 'loosely', 'defined', 'eras', '(', 'Chiron', 'as', 'a', 'child', ',', 'a', 'high', 'school-aged', 'student', ',', 'and', 'an', 'adult', ')', 'and', 'concerns', 'itself', 'equally', 'with', 'two', 'complex', 'relationships', '(', 'Chiron', 'and', 'his', 'mother', ',', 'and', 'Chiron', 'and', 'Kevin', ')', ',', 'much', 'of', 'the', 'film', 'becomes', 'little', 'more', 'than', 'a', 'montage', 'of', 'life-shaping', 'moments', '.', 'Collectively', ',', 'these', 'scenes', 'register', 'as', 'histrionic', 'because', 'there', 'are', 'only', 'broad', 'strokes', 'to', 'contextualize', 'them', '.', 'At', 'one', 'point', ',', 'a', 'neighborhood', 'drug', 'dealer', ',', 'Juan', '(', 'Mahershala', 'Ali', ')', ',', 'who', 'comes', 'to', 'mentor', 'a', 'young', 'Chiron', '(', 'Alex', 'Hibbert', ')', 'imparts', 'words', 'of', 'wisdom', 'to', 'the', 'boy', ',', 'but', 'scenes', 'later', 'he', '’', 's', 'gone', ',', 'and', 'precisely', 'what', 'his', 'interest', 'was', 'in', 'Chiron', 'is', 'left', 'unclear', '.', 'Likewise', ',', 'the', 'principal', 'characters—from', 'Chiron', '’', 's', 'mother', 'to', 'Chiron', 'himself—are', 'defined', 'almost', 'exclusively', 'by', 'their', 'roles', 'in', 'conflicts', 'and', 'reconciliations', '.', 'Harris', 'in', 'particular', 'has', 'to', 'somehow', 'create', 'a', 'believable', 'arc', 'from', 'Paula', '’', 's', 'repeated', ',', 'drug-addled', 'berating', 'and', 'one', 'late', 'scene', 'that', 'depicts', 'the', 'mother', 'soberly', 'crying', 'as', 'she', 'expresses', 'her', 'remorse', '.', 'Chiron', ',', 'meanwhile', ',', 'is', 'never', ',', 'at', 'least', 'until', 'the', 'last', 'section', 'of', 'the', 'film', ',', 'much', 'more', 'than', 'the', 'sum', 'of', 'his', 'interactions', 'with', 'other', 'people', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "file_content = open(\"Moonlight.txt\").read()\n",
    "tokens = nltk.word_tokenize(file_content)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94f2c6",
   "metadata": {},
   "source": [
    "### a. How many sentences in the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1506dfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "a=open(\"Moonlight.txt\").readlines()\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdeeb35",
   "metadata": {},
   "source": [
    "### b.How many words in file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aeab21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e66e5e3",
   "metadata": {},
   "source": [
    "### c.What are the top 10 words and their counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "520ffbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 31), ('and', 15), ('a', 14), ('the', 14), ('.', 12), ('’', 10), ('Chiron', 10), ('of', 10), ('in', 8), ('s', 8)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter = Counter(tokens)\n",
    "most_occur = Counter.most_common(10)\n",
    "  \n",
    "print(most_occur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae321a",
   "metadata": {},
   "source": [
    "### d. How many different pos tags are represented in this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa676001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\1mscdsa19\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\1mscdsa19\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a31f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CC coordinating conjunction \n",
    "CD cardinal digit \n",
    "DT determiner \n",
    "EX existential there (like: “there is” … think of it like “there exists”) \n",
    "FW foreign word \n",
    "IN preposition/subordinating conjunction \n",
    "JJ adjective – ‘big’ \n",
    "JJR adjective, comparative – ‘bigger’ \n",
    "JJS adjective, superlative – ‘biggest’ \n",
    "LS list marker 1) \n",
    "MD modal – could, will \n",
    "NN noun, singular ‘- desk’ \n",
    "NNS noun plural – ‘desks’ \n",
    "NNP proper noun, singular – ‘Harrison’ \n",
    "NNPS proper noun, plural – ‘Americans’ \n",
    "PDT predeterminer – ‘all the kids’ \n",
    "POS possessive ending parent’s \n",
    "PRP personal pronoun –  I, he, she \n",
    "PRP$ possessive pronoun – my, his, hers \n",
    "RB adverb – very, silently, \n",
    "RBR adverb, comparative – better \n",
    "RBS adverb, superlative – best \n",
    "RP particle – give up \n",
    "TO – to go ‘to’ the store. \n",
    "UH interjection – errrrrrrrm \n",
    "VB verb, base form – take \n",
    "VBD verb, past tense – took \n",
    "VBG verb, gerund/present participle – taking \n",
    "VBN verb, past participle – taken \n",
    "VBP verb, sing. present, non-3d – take \n",
    "VBZ verb, 3rd person sing. present – takes \n",
    "WDT wh-determiner – which \n",
    "WP wh-pronoun – who, what \n",
    "WP$ possessive wh-pronoun, eg- whose \n",
    "WRB wh-adverb, eg- where, when\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a023f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8231c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('best', 'JJS'), ('scene', 'NN'), ('Barry', 'NNP'), ('Jenkins', 'NNP'), ('’', 'NNP'), ('Moonlight', 'NNP'), ('also', 'RB'), ('longest', 'JJS'), ('.', '.')]\n",
      "[('It', 'PRP'), ('depicts', 'VBZ'), ('two', 'CD'), ('men', 'NNS'), (',', ','), ('boyhood', 'NN'), ('days', 'NNS'), (',', ','), ('shared', 'VBD'), ('sexual', 'JJ'), ('experience', 'NN'), ('violent', 'JJ'), ('episode', 'NN'), ('meet', 'NN'), ('years', 'NNS'), ('apart', 'RB'), ('close-to-empty', 'JJ'), ('diner', 'NN'), (',', ','), ('hesitantly', 'RB'), ('exchanging', 'VBG'), ('information', 'NN'), ('lives', 'NNS'), ('’', 'VBP'), ('lived', 'VBN'), ('interim', 'NN'), ('.', '.')]\n",
      "[('Chiron', 'NNP'), ('(', '('), ('Trevante', 'NNP'), ('Rhodes', 'NNP'), (')', ')'), ('grits', 'VBZ'), ('grillz', 'NN'), (',', ','), ('stint', 'NN'), ('juvenile', 'NN'), ('detention', 'NN'), (',', ','), ('’', 'NNP'), ('“', 'NNP'), ('trappin', 'NN'), ('’', 'NNP'), ('”', 'NNP'), (';', ':'), ('Kevin', 'NNP'), ('(', '('), ('André', 'NNP'), ('Holland', 'NNP'), (')', ')'), ('talks', 'NNS'), ('marriage', 'NN'), (',', ','), ('kids', 'NNS'), (',', ','), ('amiable', 'JJ'), ('divorce', 'NN'), ('.', '.')]\n",
      "[('Throughout', 'NN'), (',', ','), ('Jenkins', 'NNP'), ('negotiates', 'VBZ'), ('hybrid', 'JJ'), ('patient', 'NN'), (',', ','), ('real-time', 'JJ'), ('conversational', 'JJ'), ('moments', 'NNS'), ('recognizable', 'JJ'), ('Andrew', 'NNP'), ('Haigh', 'NNP'), ('Richard', 'NNP'), ('Linklater', 'NNP'), ('’', 'NNP'), ('films', 'NNS'), (',', ','), ('aesthetic', 'JJ'), ('sensualism', 'NN'), ('favored', 'VBN'), ('Wong', 'NNP'), ('Kar-wai', 'NNP'), ('Pedro', 'NNP'), ('Almodóvar', 'NNP'), ('.', '.')]\n",
      "[('It', 'PRP'), ('’', 'VBZ'), ('one', 'CD'), ('occasion', 'NN'), ('Jenkins', 'NNP'), ('gets', 'VBZ'), ('balance', 'NN'), ('right', 'NN'), (',', ','), ('allowing', 'VBG'), ('interpersonal', 'JJ'), ('intimacy', 'NN'), ('characters', 'NNS'), ('sensory', 'JJ'), ('understanding', 'JJ'), ('unspoken', 'JJ'), ('desires', 'NNS'), ('.', '.')]\n",
      "[('The', 'DT'), ('rest', 'NN'), ('Moonlight', 'NNP'), (',', ','), ('however', 'RB'), (',', ','), ('burdened', 'VBD'), ('setting', 'VBG'), ('dramatic', 'JJ'), ('weight', 'NN'), ('particular', 'JJ'), ('encounter', 'NN'), (',', ','), ('also', 'RB'), ('developing', 'VBG'), ('narrative', 'JJ'), ('leading', 'VBG'), ('toward', 'IN'), ('another', 'DT'), ('one', 'NN'), (':', ':'), ('Chiron', 'NNP'), ('’', 'NNP'), ('reunion', 'NN'), ('drug-addicted', 'JJ'), ('mother', 'NN'), (',', ','), ('Paula', 'NNP'), ('(', '('), ('Naomie', 'NNP'), ('Harris', 'NNP'), (')', ')'), ('.', '.')]\n",
      "[('Because', 'IN'), ('Jenkins', 'NNP'), ('tasked', 'VBD'), ('story', 'NN'), ('spans', 'NNS'), ('three', 'CD'), ('loosely', 'RB'), ('defined', 'VBN'), ('eras', 'NNS'), ('(', '('), ('Chiron', 'NNP'), ('child', 'NN'), (',', ','), ('high', 'JJ'), ('school-aged', 'JJ'), ('student', 'NN'), (',', ','), ('adult', 'NN'), (')', ')'), ('concerns', 'NNS'), ('equally', 'RB'), ('two', 'CD'), ('complex', 'JJ'), ('relationships', 'NNS'), ('(', '('), ('Chiron', 'NNP'), ('mother', 'NN'), (',', ','), ('Chiron', 'NNP'), ('Kevin', 'NNP'), (')', ')'), (',', ','), ('much', 'JJ'), ('film', 'NN'), ('becomes', 'VBZ'), ('little', 'JJ'), ('montage', 'JJ'), ('life-shaping', 'JJ'), ('moments', 'NNS'), ('.', '.')]\n",
      "[('Collectively', 'RB'), (',', ','), ('scenes', 'NNS'), ('register', 'VBP'), ('histrionic', 'JJ'), ('broad', 'JJ'), ('strokes', 'NNS'), ('contextualize', 'VBP'), ('.', '.')]\n",
      "[('At', 'IN'), ('one', 'CD'), ('point', 'NN'), (',', ','), ('neighborhood', 'JJ'), ('drug', 'NN'), ('dealer', 'NN'), (',', ','), ('Juan', 'NNP'), ('(', '('), ('Mahershala', 'NNP'), ('Ali', 'NNP'), (')', ')'), (',', ','), ('comes', 'VBZ'), ('mentor', 'NN'), ('young', 'JJ'), ('Chiron', 'NNP'), ('(', '('), ('Alex', 'NNP'), ('Hibbert', 'NNP'), (')', ')'), ('imparts', 'VBZ'), ('words', 'NNS'), ('wisdom', 'NN'), ('boy', 'NN'), (',', ','), ('scenes', 'NNS'), ('later', 'RB'), ('’', 'VBP'), ('gone', 'VBN'), (',', ','), ('precisely', 'RB'), ('interest', 'NN'), ('Chiron', 'NNP'), ('left', 'VBD'), ('unclear', 'JJ'), ('.', '.')]\n",
      "[('Likewise', 'RB'), (',', ','), ('principal', 'JJ'), ('characters—from', 'NN'), ('Chiron', 'NNP'), ('’', 'NNP'), ('mother', 'NN'), ('Chiron', 'NNP'), ('himself—are', 'NN'), ('defined', 'VBD'), ('almost', 'RB'), ('exclusively', 'JJ'), ('roles', 'NNS'), ('conflicts', 'NNS'), ('reconciliations', 'NNS'), ('.', '.')]\n",
      "[('Harris', 'NNP'), ('particular', 'JJ'), ('somehow', 'RB'), ('create', 'VBP'), ('believable', 'JJ'), ('arc', 'JJ'), ('Paula', 'NNP'), ('’', 'NNP'), ('repeated', 'VBD'), (',', ','), ('drug-addled', 'JJ'), ('berating', 'VBG'), ('one', 'CD'), ('late', 'JJ'), ('scene', 'NN'), ('depicts', 'VBZ'), ('mother', 'RB'), ('soberly', 'JJ'), ('crying', 'NN'), ('expresses', 'NNS'), ('remorse', 'NN'), ('.', '.')]\n",
      "[('Chiron', 'NNP'), (',', ','), ('meanwhile', 'RB'), (',', ','), ('never', 'RB'), (',', ','), ('least', 'JJS'), ('last', 'JJ'), ('section', 'NN'), ('film', 'NN'), (',', ','), ('much', 'JJ'), ('sum', 'NN'), ('interactions', 'NNS'), ('people', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "tokenized = sent_tokenize(file_content)\n",
    "for i in tokenized:\n",
    "    # Word tokenizers is used to find the words\n",
    "    # and punctuation in a string\n",
    "    wordsList = nltk.word_tokenize(i)\n",
    " \n",
    "    # removing stop words from wordList\n",
    "    wordsList = [w for w in wordsList if not w in stop_words]\n",
    " \n",
    "    #  Using a Tagger. Which is part-of-speech\n",
    "    # tagger or POS-tagger.\n",
    "    tagged = nltk.pos_tag(wordsList)\n",
    " \n",
    "    print(tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f398ce2",
   "metadata": {},
   "source": [
    "### e. What are top10 pos tags and their counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40b4f363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((',', ','), 4), (('Chiron', 'NNP'), 1), (('meanwhile', 'RB'), 1), (('never', 'RB'), 1), (('least', 'JJS'), 1), (('last', 'JJ'), 1), (('section', 'NN'), 1), (('film', 'NN'), 1), (('much', 'JJ'), 1), (('sum', 'NN'), 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter = Counter(tagged)\n",
    "most_occur = Counter.most_common(10)\n",
    "  \n",
    "print(most_occur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25e3469",
   "metadata": {},
   "source": [
    "### f. How many nouns in the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e002dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. of Nouns: 128\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(file_content) #tokenize sentences\n",
    "nouns = [] #empty to array to hold all nouns\n",
    "\n",
    "for sentence in sentences:\n",
    "     for word,pos in nltk.pos_tag(nltk.word_tokenize(str(sentence))):\n",
    "        if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'):\n",
    "             nouns.append(word)\n",
    "print(\"NO. of Nouns:\",len(nouns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21e75d",
   "metadata": {},
   "source": [
    "### g.How many verbs in the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b914cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. of Verbs: 39\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(file_content) #tokenize sentences\n",
    "verb = [] #empty to array to hold all nouns\n",
    "\n",
    "for sentence in sentences:\n",
    "     for word,pos in nltk.pos_tag(nltk.word_tokenize(str(sentence))):\n",
    "        if (pos == 'VB' or pos == 'VBD' or pos == 'VBN' or pos == 'VBP' or pos =='VBZ'):\n",
    "             verb.append(word)\n",
    "print(\"NO. of Verbs:\",len(verb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed3415",
   "metadata": {},
   "source": [
    "### h.How many adjectives in the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48f97cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. of adjectives: 39\n"
     ]
    }
   ],
   "source": [
    "adj = [] \n",
    "\n",
    "for sentence in sentences:\n",
    "     for word,pos in nltk.pos_tag(nltk.word_tokenize(str(sentence))):\n",
    "        if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS'):\n",
    "             adj.append(word)\n",
    "print(\"NO. of adjectives:\",len(adj))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b2932c",
   "metadata": {},
   "source": [
    "### i. How many adverbs in the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee3b8a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO. of adverb: 0\n"
     ]
    }
   ],
   "source": [
    "adv = [] \n",
    "\n",
    "for sentence in sentences:\n",
    "     for word,pos in nltk.pos_tag(nltk.word_tokenize(str(sentence))):\n",
    "        if (pos == 'RB' or pos == 'RBR' or pos == 'RBS' or pos == 'BP'):\n",
    "             adj.append(word)\n",
    "print(\"NO. of adverb:\",len(adv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2645e5b7",
   "metadata": {},
   "source": [
    "### j. What is the most frequent adverb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a53504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nltk \n",
    "import pandas as pd \n",
    "from nltk import * \n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b864c52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv=FreqDist(adv)\n",
    "adv.most_common(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca2693",
   "metadata": {},
   "source": [
    "### k. What is the most frequent adverb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2961638c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 2)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv=FreqDist(adj)\n",
    "adv.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514d662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
